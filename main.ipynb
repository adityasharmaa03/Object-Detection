{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2813,"status":"ok","timestamp":1690447927963,"user":{"displayName":"Aditya Sharma","userId":"15241221309814752562"},"user_tz":-330},"id":"QBXucfiswdHV","outputId":"0848444f-640f-413d-b1f7-a9f972b2f329"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15829, done.\u001b[K\n","remote: Counting objects: 100% (61/61), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 15829 (delta 21), reused 31 (delta 10), pack-reused 15768\u001b[K\n","Receiving objects: 100% (15829/15829), 14.65 MiB | 17.15 MiB/s, done.\n","Resolving deltas: 100% (10833/10833), done.\n"]}],"source":["# cloning yolov5\n","!git clone https://github.com/ultralytics/yolov5"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6775,"status":"ok","timestamp":1690447941619,"user":{"displayName":"Aditya Sharma","userId":"15241221309814752562"},"user_tz":-330},"id":"6YWefcIQyl1m","outputId":"492668aa-a450-4cbb-9f96-8bda51dce69f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m605.0/605.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["%cd yolov5\n","%pip install -qr requirements.txt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7408,"status":"ok","timestamp":1690447954275,"user":{"displayName":"Aditya Sharma","userId":"15241221309814752562"},"user_tz":-330},"id":"0ARtqSMpyl76","outputId":"435c478c-af61-4ca0-bc77-f14cd3e24a6b"},"outputs":[{"name":"stderr","output_type":"stream","text":["YOLOv5 üöÄ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"]},{"name":"stdout","output_type":"stream","text":["Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 24.2/78.2 GB disk)\n"]}],"source":["# importing pytorch and checking resources\n","import torch\n","from yolov5 import utils\n","display = utils.notebook_init()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1480752,"status":"ok","timestamp":1690449855774,"user":{"displayName":"Aditya Sharma","userId":"15241221309814752562"},"user_tz":-330},"id":"JJGn4eI5ymAk","outputId":"67c1a037-55c9-4048-8669-a6a1a887c354"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING ‚ö†Ô∏è 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n","WARNING ‚ö†Ô∏è 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n","Note this warning may be related to loading older models. You can update your model to current structure with:\n","    import torch\n","    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n","    torch.save(ckpt, \"updated-model.pt\")\n","\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=thermal_imaging_dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n","YOLOv5 üöÄ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00\u003c00:00, 230MB/s]\n","\n","Overriding model.yaml nc=80 with nc=4\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/mini_project/thermal_imaging_dataset/labels/train.cache... 1000 images, 164 backgrounds, 0 corrupt: 100% 1000/1000 [00:00\u003c?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/mini_project/thermal_imaging_dataset/labels/val.cache... 772 images, 28 backgrounds, 0 corrupt: 100% 772/772 [00:00\u003c?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /content/drive/MyDrive/mini_project/thermal_imaging_dataset/images/val/05639.jpg: 1 duplicate labels removed\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.89 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n","Plotting labels to runs/train/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/29      3.48G     0.1047    0.05311    0.03314         75        640: 100% 63/63 [00:42\u003c00:00,  1.48it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [07:46\u003c00:00, 18.64s/it]\n","                   all        772       7160      0.543     0.0625     0.0382    0.00997\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/29      3.95G    0.08328    0.04228    0.01646         64        640: 100% 63/63 [00:35\u003c00:00,  1.79it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:11\u003c00:00,  2.25it/s]\n","                   all        772       7160      0.607      0.223      0.125     0.0402\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/29      3.95G     0.0804    0.03823    0.01196         81        640: 100% 63/63 [00:33\u003c00:00,  1.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.30it/s]\n","                   all        772       7160      0.477       0.28      0.192     0.0572\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/29      3.95G     0.0738     0.0376     0.0095        118        640: 100% 63/63 [00:33\u003c00:00,  1.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.31it/s]\n","                   all        772       7160      0.444      0.287      0.157     0.0581\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/29      3.95G    0.06659    0.03784   0.008526         75        640: 100% 63/63 [00:34\u003c00:00,  1.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09\u003c00:00,  2.51it/s]\n","                   all        772       7160      0.696      0.355      0.374      0.153\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/29      3.95G    0.06236    0.03764   0.007548         72        640: 100% 63/63 [00:33\u003c00:00,  1.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.42it/s]\n","                   all        772       7160      0.736      0.362      0.395      0.166\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/29      3.95G    0.05884    0.03763   0.006979        105        640: 100% 63/63 [00:32\u003c00:00,  1.92it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.31it/s]\n","                   all        772       7160      0.716      0.353      0.383      0.155\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/29      3.95G    0.05675    0.03524   0.006498         57        640: 100% 63/63 [00:34\u003c00:00,  1.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09\u003c00:00,  2.62it/s]\n","                   all        772       7160      0.724      0.403      0.429      0.181\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/29      3.95G    0.05452    0.03633   0.005855        115        640: 100% 63/63 [00:34\u003c00:00,  1.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.35it/s]\n","                   all        772       7160      0.655        0.4      0.374      0.153\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/29      3.95G    0.05244    0.03294   0.005486         51        640: 100% 63/63 [00:32\u003c00:00,  1.93it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.32it/s]\n","                   all        772       7160      0.792      0.424      0.476      0.204\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/29      3.95G    0.05205    0.03451   0.005604         80        640: 100% 63/63 [00:32\u003c00:00,  1.94it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.28it/s]\n","                   all        772       7160      0.756      0.411      0.451       0.18\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/29      3.95G     0.0512    0.03521   0.005497         91        640: 100% 63/63 [00:34\u003c00:00,  1.82it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09\u003c00:00,  2.69it/s]\n","                   all        772       7160      0.844      0.402       0.47      0.216\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/29      3.95G    0.05019    0.03408   0.005084        117        640: 100% 63/63 [00:34\u003c00:00,  1.82it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.41it/s]\n","                   all        772       7160      0.797      0.388      0.444      0.185\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/29      3.95G    0.04855      0.033    0.00487         70        640: 100% 63/63 [00:32\u003c00:00,  1.92it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.33it/s]\n","                   all        772       7160      0.787      0.412      0.463      0.203\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/29      3.95G    0.04829    0.03475   0.004855         86        640: 100% 63/63 [00:33\u003c00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.39it/s]\n","                   all        772       7160      0.814      0.432       0.49      0.233\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/29      3.95G    0.04702    0.03309   0.004654         40        640: 100% 63/63 [00:34\u003c00:00,  1.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09\u003c00:00,  2.73it/s]\n","                   all        772       7160      0.796      0.421      0.474      0.214\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/29      3.95G    0.04709    0.03303   0.004661         69        640: 100% 63/63 [00:33\u003c00:00,  1.86it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.35it/s]\n","                   all        772       7160      0.838       0.45      0.507      0.244\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/29      3.95G    0.04645    0.03306   0.004464         62        640: 100% 63/63 [00:32\u003c00:00,  1.91it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.33it/s]\n","                   all        772       7160      0.799      0.426      0.486      0.233\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/29      3.95G    0.04522    0.03264   0.004409         83        640: 100% 63/63 [00:33\u003c00:00,  1.91it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.30it/s]\n","                   all        772       7160      0.804      0.442      0.491      0.235\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/29      3.95G    0.04524    0.03448   0.004146         87        640: 100% 63/63 [00:35\u003c00:00,  1.80it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09\u003c00:00,  2.60it/s]\n","                   all        772       7160      0.848      0.413      0.486      0.225\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/29      3.95G    0.04397    0.03397   0.004193        150        640: 100% 63/63 [00:33\u003c00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.34it/s]\n","                   all        772       7160      0.828      0.428      0.488      0.231\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/29      3.95G    0.04347    0.03208   0.004014         98        640: 100% 63/63 [00:33\u003c00:00,  1.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.33it/s]\n","                   all        772       7160      0.854      0.409      0.478      0.227\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/29      3.95G    0.04215    0.03057   0.003961        117        640: 100% 63/63 [00:34\u003c00:00,  1.84it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09\u003c00:00,  2.60it/s]\n","                   all        772       7160      0.815      0.421      0.478      0.233\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/29      3.95G    0.04112    0.03062   0.003353         81        640: 100% 63/63 [00:34\u003c00:00,  1.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09\u003c00:00,  2.53it/s]\n","                   all        772       7160      0.815      0.418      0.474      0.226\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/29      3.95G    0.04185    0.03199   0.003354         79        640: 100% 63/63 [00:33\u003c00:00,  1.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.36it/s]\n","                   all        772       7160       0.81      0.432      0.481      0.228\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/29      3.95G    0.04039    0.03093   0.003304         85        640: 100% 63/63 [00:32\u003c00:00,  1.92it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.36it/s]\n","                   all        772       7160      0.823      0.425      0.483      0.233\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/29      3.95G    0.04082    0.02974   0.003497         67        640: 100% 63/63 [00:33\u003c00:00,  1.89it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.43it/s]\n","                   all        772       7160      0.835      0.428      0.489       0.24\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/29      3.95G    0.04039    0.03135   0.003401         98        640: 100% 63/63 [00:34\u003c00:00,  1.84it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09\u003c00:00,  2.62it/s]\n","                   all        772       7160      0.817      0.435       0.49      0.238\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/29      3.95G    0.03992    0.03113    0.00321         93        640: 100% 63/63 [00:33\u003c00:00,  1.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.33it/s]\n","                   all        772       7160       0.82      0.445      0.498      0.244\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/29      3.95G    0.03974     0.0311   0.003208         55        640: 100% 63/63 [00:33\u003c00:00,  1.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10\u003c00:00,  2.37it/s]\n","                   all        772       7160      0.812      0.441      0.494      0.244\n","\n","30 epochs completed in 0.502 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:19\u003c00:00,  1.26it/s]\n","                   all        772       7160      0.837      0.449      0.506      0.244\n","               bicycle        772        280      0.783      0.436      0.484      0.186\n","                   car        772       4225      0.757      0.693      0.773      0.423\n","                   dog        772         31          1          0    0.00101   0.000525\n","                person        772       2624      0.808      0.668      0.768      0.365\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n"]}],"source":["# training yolov5 on custom dataset\n","!python train.py --img 640 --batch 16 --epochs 30 --data thermal_imaging_dataset.yaml --weights yolov5s.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDBeiE0i08Ej"},"outputs":[],"source":["# Testing the inference on a thermal video\n","#!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.35 --source /content/drive/MyDrive/mini_project/thermal_imaging_video.mp4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTNgVFyg95j3"},"outputs":[],"source":["# testing on a thermal image\n","#!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.35 --source /content/drive/MyDrive/mini_project/test_data/07847.jpg\n","\n","# def dec(path_ig):\n","#   !python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.35 --source {path_ig}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqnRhLtLSC7L"},"outputs":[],"source":["# dec('/content/drive/MyDrive/mini_project/test_data/06897.jpg')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"elapsed":9831,"status":"ok","timestamp":1690449880117,"user":{"displayName":"Aditya Sharma","userId":"15241221309814752562"},"user_tz":-330},"id":"UAnmuvMnHnPv","outputId":"6a0d9d16-9bf0-4d8b-caec-fd675876a7f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting anvil-uplink\n","  Downloading anvil_uplink-0.4.2-py2.py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m881.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting argparse (from anvil-uplink)\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.18.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n","Collecting ws4py (from anvil-uplink)\n","  Downloading ws4py-0.5.1.tar.gz (51 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: ws4py\n","  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45227 sha256=615729eb6dd3c7238c87937d76a8a43afbbd1d21fde6c30df694f24297e22217\n","  Stored in directory: /root/.cache/pip/wheels/2e/7c/ad/d9c746276bf024d44296340869fcb169f1e5d80fb147351a57\n","Successfully built ws4py\n","Installing collected packages: ws4py, argparse, anvil-uplink\n","Successfully installed anvil-uplink-0.4.2 argparse-1.4.0 ws4py-0.5.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse","google"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Connecting to wss://anvil.works/uplink\n","Anvil websocket open\n","Connected to \"Default Environment\" as SERVER\n"]}],"source":["!pip install anvil-uplink\n","import anvil.server\n","anvil.server.connect('server_M3IWTO57TJ6S6HIXULR2K565-V6F7ET7N6A5LKWFG')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1704,"status":"ok","timestamp":1690449885854,"user":{"displayName":"Aditya Sharma","userId":"15241221309814752562"},"user_tz":-330},"id":"o94gaWUhFLun"},"outputs":[],"source":["@anvil.server.callable\n","def detect_object(input_path):\n","  # testing on a thermal image\n","  print(input_path)\n","  !python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.35 --source {input_path}\n","  #print('done')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"o-GUxA7VPRRP"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/mini_project/test_data/06429.jpg\n","WARNING ‚ö†Ô∏è 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n","WARNING ‚ö†Ô∏è 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n","Note this warning may be related to loading older models. You can update your model to current structure with:\n","    import torch\n","    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n","    torch.save(ckpt, \"updated-model.pt\")\n","\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/drive/MyDrive/mini_project/test_data/06429.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.35, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 üöÄ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/1 /content/drive/MyDrive/mini_project/test_data/06429.jpg: 512x640 1 bicycle, 10 cars, 3 persons, 68.5ms\n","Speed: 0.8ms pre-process, 68.5ms inference, 105.0ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp\u001b[0m\n","/content/drive/MyDrive/mini_project/test_data/06897.jpg\n","WARNING ‚ö†Ô∏è 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n","WARNING ‚ö†Ô∏è 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n","Note this warning may be related to loading older models. You can update your model to current structure with:\n","    import torch\n","    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n","    torch.save(ckpt, \"updated-model.pt\")\n","\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/drive/MyDrive/mini_project/test_data/06897.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.35, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 üöÄ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/1 /content/drive/MyDrive/mini_project/test_data/06897.jpg: 512x640 4 cars, 2 persons, 43.0ms\n","Speed: 0.7ms pre-process, 43.0ms inference, 84.9ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"]}],"source":["anvil.server.wait_forever()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNEOIxa4PJrGUi/Jd5q6oQL","mount_file_id":"13NykGOZDFJtXGv2c8abu88eHTcMZwkHD","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}